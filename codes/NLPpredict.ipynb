{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test file for nlp packages that predict race to see acuuracy,the following are the packages using \n",
    "\n",
    "1. ethnicolr\n",
    "The model uses US census data, the Florida voting registration data, and the Wikipedia data collected by Skiena and colleagues, to predict race and ethnicity based on first and last name or just the last name. \n",
    "The model provides 06 functions. \n",
    "\n",
    "Source: https://ethnicolr.readthedocs.io/ethnicolr.html#install  \n",
    "\n",
    "\n",
    "\n",
    "The Prediction Process: \n",
    "\n",
    "owner ----> nlp ----> W: 70% NW: 30%    \n",
    "block group ... ----> W: 80% NW: 20%\n",
    "            .\n",
    "            .\n",
    "            .\n",
    "            .\n",
    "            and use\n",
    "        min & max scale? \n",
    "          ex.  \n",
    "            1 -----> 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>company_name</th>\n",
       "      <th>fullname</th>\n",
       "      <th>title</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>flag_executive</th>\n",
       "      <th>flag_owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Capital Jiu-Jitsu Team/Royce</td>\n",
       "      <td>Jeremiah Lafreniere</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Jeremiah</td>\n",
       "      <td>Lafreniere</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Integrated Clinical Concepts</td>\n",
       "      <td>Judith Wald</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Judith</td>\n",
       "      <td>Wald</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Magical Elves Inc</td>\n",
       "      <td>Ben Mack</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Ben</td>\n",
       "      <td>Mack</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Potomac River Running Store</td>\n",
       "      <td>Chris Jakubek</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Jakubek</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Atlantic Sweeping &amp; Cleaning Inc</td>\n",
       "      <td>Bonita Tenicela</td>\n",
       "      <td>Controller</td>\n",
       "      <td>Bonita</td>\n",
       "      <td>Tenicela</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29871</th>\n",
       "      <td>50399</td>\n",
       "      <td>Richard A Spagna</td>\n",
       "      <td>Richard Spagna</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Spagna</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29872</th>\n",
       "      <td>50400</td>\n",
       "      <td>Kathy Wolf MD PC</td>\n",
       "      <td>Kathy Wolf</td>\n",
       "      <td>Principal</td>\n",
       "      <td>Kathy</td>\n",
       "      <td>Wolf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29873</th>\n",
       "      <td>50401</td>\n",
       "      <td>Roger F Vorcheimer DDS</td>\n",
       "      <td>Roger Vorcheimer</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Roger</td>\n",
       "      <td>Vorcheimer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29874</th>\n",
       "      <td>50402</td>\n",
       "      <td>Richard F Blackburn</td>\n",
       "      <td>Richard Blackburn</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29875</th>\n",
       "      <td>50403</td>\n",
       "      <td>Kurt C Rommel Lawyer</td>\n",
       "      <td>Kurt Rommel</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Kurt</td>\n",
       "      <td>Rommel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29876 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                      company_name             fullname  \\\n",
       "0          2      Capital Jiu-Jitsu Team/Royce  Jeremiah Lafreniere   \n",
       "1          3      Integrated Clinical Concepts          Judith Wald   \n",
       "2          4                 Magical Elves Inc             Ben Mack   \n",
       "3          5       Potomac River Running Store        Chris Jakubek   \n",
       "4          7  Atlantic Sweeping & Cleaning Inc      Bonita Tenicela   \n",
       "...      ...                               ...                  ...   \n",
       "29871  50399                  Richard A Spagna       Richard Spagna   \n",
       "29872  50400                  Kathy Wolf MD PC           Kathy Wolf   \n",
       "29873  50401            Roger F Vorcheimer DDS     Roger Vorcheimer   \n",
       "29874  50402               Richard F Blackburn    Richard Blackburn   \n",
       "29875  50403              Kurt C Rommel Lawyer          Kurt Rommel   \n",
       "\n",
       "              title firstname    lastname  flag_executive  flag_owner  \n",
       "0             Owner  Jeremiah  Lafreniere               1           1  \n",
       "1           Manager    Judith        Wald               1           0  \n",
       "2           Manager       Ben        Mack               1           0  \n",
       "3           Manager     Chris     Jakubek               1           0  \n",
       "4        Controller    Bonita    Tenicela               1           0  \n",
       "...             ...       ...         ...             ...         ...  \n",
       "29871       Manager   Richard      Spagna               1           0  \n",
       "29872     Principal     Kathy        Wolf               1           0  \n",
       "29873  Professional     Roger  Vorcheimer               1           0  \n",
       "29874       Manager   Richard   Blackburn               1           0  \n",
       "29875         Owner      Kurt      Rommel               1           1  \n",
       "\n",
       "[29876 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#data fram we will use to test the nlp models\n",
    "az_true_df = pd.read_csv('../data/mergent_intellect_executives/AtoZ_executive_flagged.csv.xz')\n",
    "mergent = pd.read_csv(\"../data/mergent_and_library/mergent_flagged.csv.xz\")\n",
    "az_true_df\n",
    "# mergent_true_df.columns #ask about search column, what does this mean \n",
    "\n",
    "# #data frame with just the first and the last names\n",
    "# namesdf = pd.DataFrame(mergent_true_df, columns=['lastname', 'firstname'])\n",
    "# namesdf\n",
    "# #the orignal data frame contains 1067 names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnicolor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <built-in method __contains__ of dict object at 0x7f14e53dbac0> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-567958321db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0methnicolr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0methnicolr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcensus_ln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_census_ln\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#this is so i don't have to write it out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'firstname'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ethnicolr/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0methnicolr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcensus_ln\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcensus_ln\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0methnicolr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_census_ln\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpred_census_ln\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0methnicolr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_wiki_ln\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpred_wiki_ln\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0methnicolr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_wiki_name\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpred_wiki_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ethnicolr/census_ln.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0methnicolr_class\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEthnicolrModelClass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marg_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ethnicolr/ethnicolr_class.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "import ethnicolr\n",
    "from ethnicolr import census_ln, pred_census_ln\n",
    "\n",
    "#this is so i don't have to write it out\n",
    "f = 'firstname'\n",
    "l = 'lastname'\n",
    "\n",
    "fname = pd.DataFrame(az_true_df, columns=[f]) #data frame with just first names\n",
    "lname = pd.DataFrame(az_true_df, columns=[l]) #data frame with just last names\n",
    "namesdf #datafram with both first and last names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## censu_ln w/first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = census_ln(fname, f, 2010)\n",
    "\n",
    "#produces a sig. amount of null values\n",
    "#does not predict the race automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## censu_ln w/last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = census_ln(fname, f, 2010)\n",
    "\n",
    "#output is mostly null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_census_ln w firstnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 12:49:54.945096: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>api</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Craig</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>0.089045</td>\n",
       "      <td>0.024518</td>\n",
       "      <td>0.869542</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.253471</td>\n",
       "      <td>0.059234</td>\n",
       "      <td>0.674150</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.222751</td>\n",
       "      <td>0.026621</td>\n",
       "      <td>0.745203</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark</td>\n",
       "      <td>0.115171</td>\n",
       "      <td>0.152901</td>\n",
       "      <td>0.062149</td>\n",
       "      <td>0.669779</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>0.232428</td>\n",
       "      <td>0.241797</td>\n",
       "      <td>0.025657</td>\n",
       "      <td>0.500118</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4526</th>\n",
       "      <td>Kambiz</td>\n",
       "      <td>0.166088</td>\n",
       "      <td>0.118888</td>\n",
       "      <td>0.158119</td>\n",
       "      <td>0.556906</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>Wesam</td>\n",
       "      <td>0.046150</td>\n",
       "      <td>0.193775</td>\n",
       "      <td>0.026130</td>\n",
       "      <td>0.733945</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>Jal</td>\n",
       "      <td>0.299375</td>\n",
       "      <td>0.171599</td>\n",
       "      <td>0.085851</td>\n",
       "      <td>0.443175</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4529</th>\n",
       "      <td>Teel</td>\n",
       "      <td>0.026228</td>\n",
       "      <td>0.094361</td>\n",
       "      <td>0.027171</td>\n",
       "      <td>0.852241</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>Leesa</td>\n",
       "      <td>0.056587</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.837496</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4531 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     firstname       api     black  hispanic     white   race\n",
       "0        Craig  0.016894  0.089045  0.024518  0.869542  white\n",
       "1        Brian  0.013145  0.253471  0.059234  0.674150  white\n",
       "2      Richard  0.005425  0.222751  0.026621  0.745203  white\n",
       "3         Mark  0.115171  0.152901  0.062149  0.669779  white\n",
       "4         John  0.232428  0.241797  0.025657  0.500118  white\n",
       "...        ...       ...       ...       ...       ...    ...\n",
       "4526    Kambiz  0.166088  0.118888  0.158119  0.556906  white\n",
       "4527     Wesam  0.046150  0.193775  0.026130  0.733945  white\n",
       "4528       Jal  0.299375  0.171599  0.085851  0.443175  white\n",
       "4529      Teel  0.026228  0.094361  0.027171  0.852241  white\n",
       "4530     Leesa  0.056587  0.024816  0.081100  0.837496  white\n",
       "\n",
       "[4531 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf = pred_census_ln(fname, f, 2010)\n",
    "fdf\n",
    "#as you can see this model outputs only 615 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort save as ethnicolor_censu_fn_pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>white</th>\n",
       "      <th>not_white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Craig</td>\n",
       "      <td>0.869542</td>\n",
       "      <td>0.130458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian</td>\n",
       "      <td>0.674150</td>\n",
       "      <td>0.325850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard</td>\n",
       "      <td>0.745203</td>\n",
       "      <td>0.254797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark</td>\n",
       "      <td>0.669779</td>\n",
       "      <td>0.330221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>0.500118</td>\n",
       "      <td>0.499882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4526</th>\n",
       "      <td>Kambiz</td>\n",
       "      <td>0.556906</td>\n",
       "      <td>0.443094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>Wesam</td>\n",
       "      <td>0.733945</td>\n",
       "      <td>0.266055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>Jal</td>\n",
       "      <td>0.443175</td>\n",
       "      <td>0.556825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4529</th>\n",
       "      <td>Teel</td>\n",
       "      <td>0.852241</td>\n",
       "      <td>0.147759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>Leesa</td>\n",
       "      <td>0.837496</td>\n",
       "      <td>0.162504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4531 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     firstname     white  not_white  race\n",
       "0        Craig  0.869542   0.130458     0\n",
       "1        Brian  0.674150   0.325850     0\n",
       "2      Richard  0.745203   0.254797     0\n",
       "3         Mark  0.669779   0.330221     0\n",
       "4         John  0.500118   0.499882     0\n",
       "...        ...       ...        ...   ...\n",
       "4526    Kambiz  0.556906   0.443094     0\n",
       "4527     Wesam  0.733945   0.266055     0\n",
       "4528       Jal  0.443175   0.556825     1\n",
       "4529      Teel  0.852241   0.147759     0\n",
       "4530     Leesa  0.837496   0.162504     0\n",
       "\n",
       "[4531 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort to binary classification w first names\n",
    "#using the pred_census_fn(fname, l, 2010) data frame w/ prediction, i am transforming the data into something useful for the proj. \n",
    "d = pd.DataFrame(fdf, columns=[f, 'white'])\n",
    "d['not_white']= 1-d['white']\n",
    "\n",
    "\n",
    "racelist = list(fdf['race'])\n",
    "notw = list(d['not_white']) \n",
    "race = []\n",
    "\n",
    "for n in notw:\n",
    "    if n > .50:\n",
    "        #print(True)\n",
    "        race.append(1)\n",
    "    else:\n",
    "        #print(False)  \n",
    "        race.append(0)\n",
    "\n",
    "race\n",
    "d['race'] = race\n",
    "d\n",
    "\n",
    "#I added a prop not_white column and made it so that the race column used boolean values:\n",
    "#1 if minority \n",
    "#0 if white\n",
    "\n",
    "#i can do this for the firstname input of the function upon request as well\n",
    "\n",
    "#save as ethnicolor_censu_fn_predictions.csv\n",
    "#615 results, not many null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_census_ln w lastnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = pred_census_ln(lname, l, 2010)\n",
    "\n",
    "#actually predicts race in an output\n",
    "#first names work too but the output is diff and produces smaller row number (predictions) - 615 to be exact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort save as ethnicolor_censu_ln_pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastname</th>\n",
       "      <th>white</th>\n",
       "      <th>not_white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abod</td>\n",
       "      <td>0.756722</td>\n",
       "      <td>0.243278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soliday</td>\n",
       "      <td>0.656425</td>\n",
       "      <td>0.343575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maigue</td>\n",
       "      <td>0.808320</td>\n",
       "      <td>0.191680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mills</td>\n",
       "      <td>0.793126</td>\n",
       "      <td>0.206874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lee</td>\n",
       "      <td>0.360847</td>\n",
       "      <td>0.639153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10192</th>\n",
       "      <td>Fondaco</td>\n",
       "      <td>0.776765</td>\n",
       "      <td>0.223235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10193</th>\n",
       "      <td>Adeler</td>\n",
       "      <td>0.774511</td>\n",
       "      <td>0.225489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10194</th>\n",
       "      <td>Faraone</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.195474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>Cryan</td>\n",
       "      <td>0.887995</td>\n",
       "      <td>0.112005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>Popovich</td>\n",
       "      <td>0.968413</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10197 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lastname     white  not_white  race\n",
       "0          Abod  0.756722   0.243278     0\n",
       "1       Soliday  0.656425   0.343575     0\n",
       "2        Maigue  0.808320   0.191680     0\n",
       "3         Mills  0.793126   0.206874     0\n",
       "4           Lee  0.360847   0.639153     1\n",
       "...         ...       ...        ...   ...\n",
       "10192   Fondaco  0.776765   0.223235     0\n",
       "10193    Adeler  0.774511   0.225489     0\n",
       "10194   Faraone  0.804526   0.195474     0\n",
       "10195     Cryan  0.887995   0.112005     0\n",
       "10196  Popovich  0.968413   0.031587     0\n",
       "\n",
       "[10197 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#using the pred_census_ln(lname, l, 2010) data frame w/ prediction, i am transforming the data into something useful for the proj. \n",
    "dd = pd.DataFrame(ldf, columns=[l, 'white'])\n",
    "notw = list(1-dd['white'])\n",
    "dd['not_white'] = notw\n",
    "\n",
    "race = list(list(ldf['race']))\n",
    "\n",
    "newlist = []\n",
    "for r in race:\n",
    "    newlist.append(str(r))\n",
    "newlist\n",
    "\n",
    "correct = []\n",
    "for n in list(dd['not_white']):\n",
    "    if .50 < n < 1.00:\n",
    "        #print(True)\n",
    "        correct.append(1)\n",
    "    else:\n",
    "        #print(False)  \n",
    "        correct.append(0)\n",
    "\n",
    "\n",
    "dd['race'] = correct\n",
    "dd\n",
    "\n",
    "\n",
    "#i can do this for the firstname input of the function upon request as well\n",
    "#save as ethnicolor_censu_ln_predictions.csv\n",
    "#916 results no visible null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_wiki_ln w/ firstnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asian,GreaterEastAsian,EastAsian', 'Asian,GreaterEastAsian,Japanese', 'Asian,IndianSubContinent', 'GreaterAfrican,Africans', 'GreaterAfrican,Muslim', 'GreaterEuropean,British', 'GreaterEuropean,EastEuropean', 'GreaterEuropean,Jewish', 'GreaterEuropean,WestEuropean,French', 'GreaterEuropean,WestEuropean,Germanic', 'GreaterEuropean,WestEuropean,Hispanic', 'GreaterEuropean,WestEuropean,Italian', 'GreaterEuropean,WestEuropean,Nordic']\n"
     ]
    }
   ],
   "source": [
    "from ethnicolr import pred_wiki_ln, pred_wiki_name\n",
    "wikifirstdf = pred_wiki_ln(fname, f, num_iter=100, conf_int=.90)\n",
    "#i like how this function has a confidence interval input \n",
    "wikifirstdf\n",
    "\n",
    "white = ['GreaterEuropean,WestEuropean,Italian_mean', 'GreaterEuropean,WestEuropean,Nordic_mean', \n",
    "          'GreaterEuropean,WestEuropean,Germanic_mean', 'GreaterEuropean,WestEuropean,French_mean',\n",
    "          'GreaterEuropean,Jewish_mean', 'GreaterEuropean,British_mean','GreaterEuropean,EastEuropean_mean']\n",
    "whitelist = ['GreaterEuropean,WestEuropean,Italian', 'GreaterEuropean,WestEuropean,Nordic',\n",
    "         'GreaterEuropean,WestEuropean,Germanic', 'GreaterEuropean,WestEuropean,French',\n",
    "          'GreaterEuropean,Jewish', 'GreaterEuropean,British', 'GreaterEuropean,EastEuropean']\n",
    "\n",
    "#this does not produce many predictions with the first name --> 615\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort save as ethnicolor_wiki_fn_pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>white</th>\n",
       "      <th>not_white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Craig</td>\n",
       "      <td>0.290668</td>\n",
       "      <td>0.709332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian</td>\n",
       "      <td>0.350805</td>\n",
       "      <td>0.649195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard</td>\n",
       "      <td>0.466819</td>\n",
       "      <td>0.533181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark</td>\n",
       "      <td>0.441089</td>\n",
       "      <td>0.558911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>0.283046</td>\n",
       "      <td>0.716954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>Kambiz</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>Wesam</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>Jal</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>Teel</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>Leesa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4522 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     firstname     white  not_white  race\n",
       "0        Craig  0.290668   0.709332     1\n",
       "1        Brian  0.350805   0.649195     1\n",
       "2      Richard  0.466819   0.533181     1\n",
       "3         Mark  0.441089   0.558911     1\n",
       "4         John  0.283046   0.716954     1\n",
       "...        ...       ...        ...   ...\n",
       "4517    Kambiz  0.000000   1.000000     0\n",
       "4518     Wesam  0.000000   1.000000     0\n",
       "4519       Jal  0.000000   1.000000     0\n",
       "4520      Teel  0.000000   1.000000     0\n",
       "4521     Leesa  0.000000   1.000000     0\n",
       "\n",
       "[4522 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort into binary classification\n",
    "\n",
    "testfndf = pd.DataFrame(wikifirstdf, columns=[f])\n",
    "testfndf['white'] = wikifirstdf[white].sum(axis=1)\n",
    "testfndf['not_white'] = 1- testfndf['white']\n",
    "testfndf['race'] = wikifirstdf['race']\n",
    "\n",
    "\n",
    "race = []\n",
    "\n",
    "for n in list(testfndf['not_white']):\n",
    "    if .50 < n < 1.00:\n",
    "        #print(True)\n",
    "        race.append(1)\n",
    "    else:\n",
    "        #print(False)  \n",
    "        race.append(0)\n",
    "\n",
    "testfndf['race'] = race\n",
    "testfndf\n",
    "#save as ethnicolor_wiki_fn_predictions.csv\n",
    "#null values:\n",
    "#defalut is 1.00 not_white and for thre race column, but the defult od race column will be zero : white and not a minority "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_wiki_ln w/lastnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asian,GreaterEastAsian,EastAsian', 'Asian,GreaterEastAsian,Japanese', 'Asian,IndianSubContinent', 'GreaterAfrican,Africans', 'GreaterAfrican,Muslim', 'GreaterEuropean,British', 'GreaterEuropean,EastEuropean', 'GreaterEuropean,Jewish', 'GreaterEuropean,WestEuropean,French', 'GreaterEuropean,WestEuropean,Germanic', 'GreaterEuropean,WestEuropean,Hispanic', 'GreaterEuropean,WestEuropean,Italian', 'GreaterEuropean,WestEuropean,Nordic']\n"
     ]
    }
   ],
   "source": [
    "wikilastdf = pred_wiki_ln(lname, l, num_iter=100, conf_int=.90)\n",
    "\n",
    "#this produces more predictions than the first name -->917"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort save as ethnicolor_wiki_ln_pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastname</th>\n",
       "      <th>white</th>\n",
       "      <th>not_white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abod</td>\n",
       "      <td>0.809557</td>\n",
       "      <td>0.190443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soliday</td>\n",
       "      <td>0.773389</td>\n",
       "      <td>0.226611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maigue</td>\n",
       "      <td>0.978236</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mills</td>\n",
       "      <td>0.125584</td>\n",
       "      <td>0.874416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lee</td>\n",
       "      <td>0.082742</td>\n",
       "      <td>0.917258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>Fondaco</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10165</th>\n",
       "      <td>Adeler</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10166</th>\n",
       "      <td>Faraone</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10167</th>\n",
       "      <td>Cryan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10168</th>\n",
       "      <td>Popovich</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10169 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lastname     white  not_white  race\n",
       "0          Abod  0.809557   0.190443     0\n",
       "1       Soliday  0.773389   0.226611     0\n",
       "2        Maigue  0.978236   0.021764     0\n",
       "3         Mills  0.125584   0.874416     1\n",
       "4           Lee  0.082742   0.917258     1\n",
       "...         ...       ...        ...   ...\n",
       "10164   Fondaco  0.000000   1.000000     1\n",
       "10165    Adeler  0.000000   1.000000     1\n",
       "10166   Faraone  0.000000   1.000000     1\n",
       "10167     Cryan  0.000000   1.000000     1\n",
       "10168  Popovich  0.000000   1.000000     1\n",
       "\n",
       "[10169 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort into binary classification\n",
    "\n",
    "\n",
    "\n",
    "testlndf = pd.DataFrame(wikilastdf, columns=[l])\n",
    "testlndf['white'] = wikilastdf[white].sum(axis=1)\n",
    "testlndf['not_white'] = 1- testlndf['white']\n",
    "testlndf['race'] = wikilastdf['race']\n",
    "\n",
    "\n",
    "\n",
    "race = []\n",
    "\n",
    "for n in list(testlndf['not_white']):\n",
    "    if n > .50:\n",
    "        #print(True)\n",
    "        race.append(1)\n",
    "    else:\n",
    "        #print(False)  \n",
    "        race.append(0)\n",
    "\n",
    "testlndf['race'] = race\n",
    "testlndf\n",
    "#save as ethnicolor_wiki_last_predictions.csv\n",
    "#null values:\n",
    "#defalut is 1.00 not_white and for thre race column thats automatcially gunna be 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_wiki_name (this takes both the first and last names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asian,GreaterEastAsian,EastAsian', 'Asian,GreaterEastAsian,Japanese', 'Asian,IndianSubContinent', 'GreaterAfrican,Africans', 'GreaterAfrican,Muslim', 'GreaterEuropean,British', 'GreaterEuropean,EastEuropean', 'GreaterEuropean,Jewish', 'GreaterEuropean,WestEuropean,French', 'GreaterEuropean,WestEuropean,Germanic', 'GreaterEuropean,WestEuropean,Hispanic', 'GreaterEuropean,WestEuropean,Italian', 'GreaterEuropean,WestEuropean,Nordic']\n"
     ]
    }
   ],
   "source": [
    "from ethnicolr import pred_wiki_ln, pred_wiki_name\n",
    "wikifulldf = pred_wiki_name(namesdf,l, f, conf_int=0.9)\n",
    "\n",
    "\n",
    "#produces some null values but it does list most items from the original dataframe, most likely because it uses both names  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort save as ethnicolor_wiki_full_pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>white</th>\n",
       "      <th>not_white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Craig</td>\n",
       "      <td>Abod</td>\n",
       "      <td>0.962599</td>\n",
       "      <td>0.037401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Soliday</td>\n",
       "      <td>0.933843</td>\n",
       "      <td>0.066157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Maigue</td>\n",
       "      <td>0.978557</td>\n",
       "      <td>0.021443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark</td>\n",
       "      <td>Mills</td>\n",
       "      <td>0.841128</td>\n",
       "      <td>0.158872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>Lee</td>\n",
       "      <td>0.179319</td>\n",
       "      <td>0.820681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16305</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16306</th>\n",
       "      <td>Pamela</td>\n",
       "      <td>French</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16307</th>\n",
       "      <td>Leesa</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16308</th>\n",
       "      <td>Tim</td>\n",
       "      <td>Donner</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16309</th>\n",
       "      <td>Marc</td>\n",
       "      <td>Herman</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16310 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      firstname lastname     white  not_white  race\n",
       "0         Craig     Abod  0.962599   0.037401     0\n",
       "1         Brian  Soliday  0.933843   0.066157     0\n",
       "2       Richard   Maigue  0.978557   0.021443     0\n",
       "3          Mark    Mills  0.841128   0.158872     0\n",
       "4          John      Lee  0.179319   0.820681     1\n",
       "...         ...      ...       ...        ...   ...\n",
       "16305   Michael   Arthur  0.000000   1.000000     0\n",
       "16306    Pamela   French  0.000000   1.000000     0\n",
       "16307     Leesa    Kelly  0.000000   1.000000     0\n",
       "16308       Tim   Donner  0.000000   1.000000     0\n",
       "16309      Marc   Herman  0.000000   1.000000     0\n",
       "\n",
       "[16310 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort into binary classification\n",
    "#output is ethnicity, here is the list, each have mean, upper, lower bound, and standard error, we will be using the mean \n",
    "#percentages\n",
    "# ethnicitylist = ['Asian,GreaterEastAsian,EastAsian', 'Asian,GreaterEastAsian,Japanese',\n",
    "# 'Asian,IndianSubContinent', 'GreaterAfrican,Africans', 'GreaterAfrican,Muslim',\n",
    "#  'GreaterEuropean,British', 'GreaterEuropean,EastEuropean',\n",
    "#  'GreaterEuropean,Jewish', 'GreaterEuropean,WestEuropean,French', \n",
    "#  'GreaterEuropean,WestEuropean,Germanic', 'GreaterEuropean,WestEuropean,Hispanic', \n",
    "#  'GreaterEuropean,WestEuropean,Italian', 'GreaterEuropean,WestEuropean,Nordic']\n",
    "\n",
    "\n",
    "a = pd.DataFrame(wikifulldf, columns=[f, l])\n",
    "\n",
    "\n",
    "a['white'] = wikifulldf[white].sum(axis=1)\n",
    "a['not_white'] = 1- a['white']\n",
    "a['race'] = wikifulldf['race']\n",
    "\n",
    "\n",
    "\n",
    "race = []\n",
    "\n",
    "for n in list(a['not_white']):\n",
    "    if .50 < n < 1.00:\n",
    "        #print(True)\n",
    "        race.append(1)\n",
    "    else:\n",
    "        #print(False)  \n",
    "        race.append(0)\n",
    " \n",
    "\n",
    "a['race'] = race\n",
    "a\n",
    "\n",
    "#save as ethnicolor_wiki_full_predictions.csv\n",
    "#null values:\n",
    "#defalut is 1.00 not_white and for thre race column thats automatcially gunna be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_fl_reg_ln(df, namecol, num_iter=100, conf_int=1.0) w/lastname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian', 'hispanic', 'nh_black', 'nh_white']\n"
     ]
    }
   ],
   "source": [
    "from ethnicolr import pred_fl_reg_ln, pred_fl_reg_name, pred_fl_reg_ln_five_cat, pred_fl_reg_name_five_cat\n",
    "odf = pred_fl_reg_ln(ldf, l, num_iter=100, conf_int=.90)\n",
    "\n",
    "#Output: Appends the following columns to the pandas DataFrame or CSV: \n",
    "#race (white, black, asian, or hispanic), asian (percentage chance Asian), hispanic, nh_black, nh_white.\n",
    "#For each race it will provide the mean, standard error, lower & upper bound of confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort save as ethnicolor_fl_ln_pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastname</th>\n",
       "      <th>white</th>\n",
       "      <th>not_white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abod</td>\n",
       "      <td>0.756722</td>\n",
       "      <td>0.243278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soliday</td>\n",
       "      <td>0.656425</td>\n",
       "      <td>0.343575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maigue</td>\n",
       "      <td>0.808320</td>\n",
       "      <td>0.191680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mills</td>\n",
       "      <td>0.793126</td>\n",
       "      <td>0.206874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lee</td>\n",
       "      <td>0.360847</td>\n",
       "      <td>0.639153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>Fondaco</td>\n",
       "      <td>0.776765</td>\n",
       "      <td>0.223235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10165</th>\n",
       "      <td>Adeler</td>\n",
       "      <td>0.774511</td>\n",
       "      <td>0.225489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10166</th>\n",
       "      <td>Faraone</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.195474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10167</th>\n",
       "      <td>Cryan</td>\n",
       "      <td>0.887995</td>\n",
       "      <td>0.112005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10168</th>\n",
       "      <td>Popovich</td>\n",
       "      <td>0.968413</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10169 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lastname     white  not_white  race\n",
       "0          Abod  0.756722   0.243278     0\n",
       "1       Soliday  0.656425   0.343575     0\n",
       "2        Maigue  0.808320   0.191680     0\n",
       "3         Mills  0.793126   0.206874     0\n",
       "4           Lee  0.360847   0.639153     1\n",
       "...         ...       ...        ...   ...\n",
       "10164   Fondaco  0.776765   0.223235     0\n",
       "10165    Adeler  0.774511   0.225489     0\n",
       "10166   Faraone  0.804526   0.195474     0\n",
       "10167     Cryan  0.887995   0.112005     0\n",
       "10168  Popovich  0.968413   0.031587     0\n",
       "\n",
       "[10169 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstdf = pd.DataFrame( columns=[l, 'white'])\n",
    "tstdf\n",
    "ls = list(lname[l])\n",
    "tstdf[l] = ls\n",
    "tstdf['white'] = odf['white']\n",
    "tstdf['not_white'] = 1 - tstdf['white']\n",
    "tstdf['race'] = odf['race_x']\n",
    "\n",
    "\n",
    "race = []\n",
    "\n",
    "for n in list(tstdf['not_white']):\n",
    "    if n > .50:\n",
    "        #print(True)\n",
    "        race.append(1)\n",
    "    else:\n",
    "        #print(False)  \n",
    "        race.append(0)\n",
    " \n",
    "\n",
    "tstdf['race'] = race\n",
    "tstdf\n",
    "\n",
    "#917 results, don't see null values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  pred_fl_reg_name(df, 'last', 'first', conf_int=0.9) w fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian', 'hispanic', 'nh_black', 'nh_white']\n"
     ]
    }
   ],
   "source": [
    "odf = pred_fl_reg_name(namesdf, l, f, conf_int=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort save as ethnicolor_fl_full_pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>white</th>\n",
       "      <th>not_white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Craig</td>\n",
       "      <td>Abod</td>\n",
       "      <td>0.892971</td>\n",
       "      <td>0.107029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Soliday</td>\n",
       "      <td>0.699795</td>\n",
       "      <td>0.300205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Maigue</td>\n",
       "      <td>0.886724</td>\n",
       "      <td>0.113276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark</td>\n",
       "      <td>Mills</td>\n",
       "      <td>0.752849</td>\n",
       "      <td>0.247151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>Lee</td>\n",
       "      <td>0.240414</td>\n",
       "      <td>0.759586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16305</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16306</th>\n",
       "      <td>Pamela</td>\n",
       "      <td>French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16307</th>\n",
       "      <td>Leesa</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16308</th>\n",
       "      <td>Tim</td>\n",
       "      <td>Donner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16309</th>\n",
       "      <td>Marc</td>\n",
       "      <td>Herman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16310 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      firstname lastname     white  not_white  race\n",
       "0         Craig     Abod  0.892971   0.107029     0\n",
       "1         Brian  Soliday  0.699795   0.300205     0\n",
       "2       Richard   Maigue  0.886724   0.113276     0\n",
       "3          Mark    Mills  0.752849   0.247151     0\n",
       "4          John      Lee  0.240414   0.759586     1\n",
       "...         ...      ...       ...        ...   ...\n",
       "16305   Michael   Arthur       NaN        NaN     0\n",
       "16306    Pamela   French       NaN        NaN     0\n",
       "16307     Leesa    Kelly       NaN        NaN     0\n",
       "16308       Tim   Donner       NaN        NaN     0\n",
       "16309      Marc   Herman       NaN        NaN     0\n",
       "\n",
       "[16310 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pd.DataFrame(odf, columns=[f, l])\n",
    "b['white'] = odf['nh_white_mean']\n",
    "b['not_white'] = 1 - b['white']\n",
    "b['race'] = odf['race']\n",
    "\n",
    "\n",
    "race = []\n",
    "\n",
    "        \n",
    "\n",
    "for n in list(b['not_white']):\n",
    "    if n > .50:\n",
    "        #print(True)\n",
    "        race.append(1)\n",
    "    else:\n",
    "        #print(False)  \n",
    "        race.append(0)\n",
    " \n",
    "\n",
    "b['race'] = race\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 more functions then next package finally "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_fl_reg_ln_five_cat takes a last name input but ends up using the full name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian', 'hispanic', 'nh_black', 'nh_white', 'other']\n"
     ]
    }
   ],
   "source": [
    "cdf = pred_fl_reg_ln_five_cat(namesdf, l, num_iter=100, conf_int=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort and save as ethnicolor_fl_full2_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = pd.DataFrame(cdf, columns=[f, l])\n",
    "# c['white'] = cdf['nh_white_mean']\n",
    "# c['not_white'] = 1 - c['white']\n",
    "# c['race'] = cdf['race']\n",
    "\n",
    "# racelist = list(c['race'])\n",
    "# race = []\n",
    "\n",
    "        \n",
    "\n",
    "# for n in list(c['not_white']):\n",
    "#     if n > .50:\n",
    "#         #print(True)\n",
    "#         race.append(1)\n",
    "#     else:\n",
    "#         #print(False)  \n",
    "#         race.append(0)\n",
    " \n",
    "\n",
    "# c['race'] = race\n",
    "# c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_fl_reg_name_five_cat(df, namecol, num_iter=100, conf_int=1.0) w/full name input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian', 'hispanic', 'nh_black', 'nh_white', 'other']\n"
     ]
    }
   ],
   "source": [
    "rdf = pred_fl_reg_name_five_cat(namesdf, l, f, num_iter=100, conf_int=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>white</th>\n",
       "      <th>not_white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Craig</td>\n",
       "      <td>Abod</td>\n",
       "      <td>0.566501</td>\n",
       "      <td>0.433499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Soliday</td>\n",
       "      <td>0.330433</td>\n",
       "      <td>0.669567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Maigue</td>\n",
       "      <td>0.500883</td>\n",
       "      <td>0.499117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark</td>\n",
       "      <td>Mills</td>\n",
       "      <td>0.224351</td>\n",
       "      <td>0.775649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>Lee</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.980627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10185</th>\n",
       "      <td>Sal</td>\n",
       "      <td>Fondaco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10186</th>\n",
       "      <td>George</td>\n",
       "      <td>Adeler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10187</th>\n",
       "      <td>Debra</td>\n",
       "      <td>Faraone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10188</th>\n",
       "      <td>Eric</td>\n",
       "      <td>Cryan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10189</th>\n",
       "      <td>Gary</td>\n",
       "      <td>Popovich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10190 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      firstname  lastname     white  not_white  race\n",
       "0         Craig      Abod  0.566501   0.433499     0\n",
       "1         Brian   Soliday  0.330433   0.669567     1\n",
       "2       Richard    Maigue  0.500883   0.499117     0\n",
       "3          Mark     Mills  0.224351   0.775649     1\n",
       "4          John       Lee  0.019373   0.980627     1\n",
       "...         ...       ...       ...        ...   ...\n",
       "10185       Sal   Fondaco       NaN        NaN     0\n",
       "10186    George    Adeler       NaN        NaN     0\n",
       "10187     Debra   Faraone       NaN        NaN     0\n",
       "10188      Eric     Cryan       NaN        NaN     0\n",
       "10189      Gary  Popovich       NaN        NaN     0\n",
       "\n",
       "[10190 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.DataFrame(rdf, columns=[f, l])\n",
    "c['white'] = rdf['nh_white_mean']\n",
    "c['not_white'] = 1 - c['white']\n",
    "c['race'] = rdf['race']\n",
    "\n",
    "racelist = list(c['race'])\n",
    "race = []\n",
    "\n",
    "        \n",
    "\n",
    "for n in list(c['not_white']):\n",
    "    if n > .50:\n",
    "        #print(True)\n",
    "        race.append(1)\n",
    "    else:\n",
    "        #print(False)  \n",
    "        race.append(0)\n",
    " \n",
    "\n",
    "c['race'] = race\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_nc_reg_name(df, namecol, num_iter=100, conf_int=1.0) w/ full names \n",
    "### but it says nc here...are they using north carolina voter registration data? I looked all over the website as well. I tried to load a page that was linked to the \"full name NC model\" to see what it was about and it returned an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 12:57:45.116828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-21 12:57:45.118614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-21 12:57:45.119773: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HL+A', 'HL+B', 'HL+I', 'HL+M', 'HL+O', 'HL+W', 'NL+A', 'NL+B', 'NL+I', 'NL+M', 'NL+O', 'NL+W']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastname</th>\n",
       "      <th>firstname</th>\n",
       "      <th>HL+A_mean</th>\n",
       "      <th>HL+A_std</th>\n",
       "      <th>HL+A_lb</th>\n",
       "      <th>HL+A_ub</th>\n",
       "      <th>HL+B_mean</th>\n",
       "      <th>HL+B_std</th>\n",
       "      <th>HL+B_lb</th>\n",
       "      <th>HL+B_ub</th>\n",
       "      <th>...</th>\n",
       "      <th>NL+M_ub</th>\n",
       "      <th>NL+O_mean</th>\n",
       "      <th>NL+O_std</th>\n",
       "      <th>NL+O_lb</th>\n",
       "      <th>NL+O_ub</th>\n",
       "      <th>NL+W_mean</th>\n",
       "      <th>NL+W_std</th>\n",
       "      <th>NL+W_lb</th>\n",
       "      <th>NL+W_ub</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abod</td>\n",
       "      <td>Craig</td>\n",
       "      <td>2.833178e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.833178e-11</td>\n",
       "      <td>2.833178e-11</td>\n",
       "      <td>1.299032e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.299032e-08</td>\n",
       "      <td>1.299032e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.097475e-06</td>\n",
       "      <td>0.275574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275574</td>\n",
       "      <td>0.275574</td>\n",
       "      <td>0.313212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313212</td>\n",
       "      <td>0.313212</td>\n",
       "      <td>NL+W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soliday</td>\n",
       "      <td>Brian</td>\n",
       "      <td>1.344512e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344512e-11</td>\n",
       "      <td>1.344512e-11</td>\n",
       "      <td>4.788999e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.788999e-11</td>\n",
       "      <td>4.788999e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038537e-10</td>\n",
       "      <td>0.008347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008347</td>\n",
       "      <td>0.008347</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>HL+M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maigue</td>\n",
       "      <td>Richard</td>\n",
       "      <td>1.238406e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.238406e-10</td>\n",
       "      <td>1.238406e-10</td>\n",
       "      <td>2.196076e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.196076e-07</td>\n",
       "      <td>2.196076e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>7.705532e-04</td>\n",
       "      <td>0.036048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036048</td>\n",
       "      <td>0.036048</td>\n",
       "      <td>0.108246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108246</td>\n",
       "      <td>0.108246</td>\n",
       "      <td>NL+I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mills</td>\n",
       "      <td>Mark</td>\n",
       "      <td>8.189762e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.189762e-08</td>\n",
       "      <td>8.189762e-08</td>\n",
       "      <td>1.556497e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.556497e-05</td>\n",
       "      <td>1.556497e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>9.926235e-04</td>\n",
       "      <td>0.062795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062795</td>\n",
       "      <td>0.062795</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>NL+A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lee</td>\n",
       "      <td>John</td>\n",
       "      <td>7.917655e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.917655e-13</td>\n",
       "      <td>7.917655e-13</td>\n",
       "      <td>7.453077e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.453077e-04</td>\n",
       "      <td>7.453077e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.132217e-04</td>\n",
       "      <td>0.660733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660733</td>\n",
       "      <td>0.660733</td>\n",
       "      <td>0.009487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009487</td>\n",
       "      <td>0.009487</td>\n",
       "      <td>NL+O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10185</th>\n",
       "      <td>Fondaco</td>\n",
       "      <td>Sal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10186</th>\n",
       "      <td>Adeler</td>\n",
       "      <td>George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10187</th>\n",
       "      <td>Faraone</td>\n",
       "      <td>Debra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10188</th>\n",
       "      <td>Cryan</td>\n",
       "      <td>Eric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10189</th>\n",
       "      <td>Popovich</td>\n",
       "      <td>Gary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10190 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lastname firstname     HL+A_mean  HL+A_std       HL+A_lb       HL+A_ub  \\\n",
       "0          Abod     Craig  2.833178e-11       0.0  2.833178e-11  2.833178e-11   \n",
       "1       Soliday     Brian  1.344512e-11       0.0  1.344512e-11  1.344512e-11   \n",
       "2        Maigue   Richard  1.238406e-10       0.0  1.238406e-10  1.238406e-10   \n",
       "3         Mills      Mark  8.189762e-08       0.0  8.189762e-08  8.189762e-08   \n",
       "4           Lee      John  7.917655e-13       0.0  7.917655e-13  7.917655e-13   \n",
       "...         ...       ...           ...       ...           ...           ...   \n",
       "10185   Fondaco       Sal           NaN       NaN           NaN           NaN   \n",
       "10186    Adeler    George           NaN       NaN           NaN           NaN   \n",
       "10187   Faraone     Debra           NaN       NaN           NaN           NaN   \n",
       "10188     Cryan      Eric           NaN       NaN           NaN           NaN   \n",
       "10189  Popovich      Gary           NaN       NaN           NaN           NaN   \n",
       "\n",
       "          HL+B_mean  HL+B_std       HL+B_lb       HL+B_ub  ...       NL+M_ub  \\\n",
       "0      1.299032e-08       0.0  1.299032e-08  1.299032e-08  ...  3.097475e-06   \n",
       "1      4.788999e-11       0.0  4.788999e-11  4.788999e-11  ...  1.038537e-10   \n",
       "2      2.196076e-07       0.0  2.196076e-07  2.196076e-07  ...  7.705532e-04   \n",
       "3      1.556497e-05       0.0  1.556497e-05  1.556497e-05  ...  9.926235e-04   \n",
       "4      7.453077e-04       0.0  7.453077e-04  7.453077e-04  ...  3.132217e-04   \n",
       "...             ...       ...           ...           ...  ...           ...   \n",
       "10185           NaN       NaN           NaN           NaN  ...           NaN   \n",
       "10186           NaN       NaN           NaN           NaN  ...           NaN   \n",
       "10187           NaN       NaN           NaN           NaN  ...           NaN   \n",
       "10188           NaN       NaN           NaN           NaN  ...           NaN   \n",
       "10189           NaN       NaN           NaN           NaN  ...           NaN   \n",
       "\n",
       "       NL+O_mean  NL+O_std   NL+O_lb   NL+O_ub  NL+W_mean  NL+W_std   NL+W_lb  \\\n",
       "0       0.275574       0.0  0.275574  0.275574   0.313212       0.0  0.313212   \n",
       "1       0.008347       0.0  0.008347  0.008347   0.000579       0.0  0.000579   \n",
       "2       0.036048       0.0  0.036048  0.036048   0.108246       0.0  0.108246   \n",
       "3       0.062795       0.0  0.062795  0.062795   0.018194       0.0  0.018194   \n",
       "4       0.660733       0.0  0.660733  0.660733   0.009487       0.0  0.009487   \n",
       "...          ...       ...       ...       ...        ...       ...       ...   \n",
       "10185        NaN       NaN       NaN       NaN        NaN       NaN       NaN   \n",
       "10186        NaN       NaN       NaN       NaN        NaN       NaN       NaN   \n",
       "10187        NaN       NaN       NaN       NaN        NaN       NaN       NaN   \n",
       "10188        NaN       NaN       NaN       NaN        NaN       NaN       NaN   \n",
       "10189        NaN       NaN       NaN       NaN        NaN       NaN       NaN   \n",
       "\n",
       "        NL+W_ub  race  \n",
       "0      0.313212  NL+W  \n",
       "1      0.000579  HL+M  \n",
       "2      0.108246  NL+I  \n",
       "3      0.018194  NL+A  \n",
       "4      0.009487  NL+O  \n",
       "...         ...   ...  \n",
       "10185       NaN   NaN  \n",
       "10186       NaN   NaN  \n",
       "10187       NaN   NaN  \n",
       "10188       NaN   NaN  \n",
       "10189       NaN   NaN  \n",
       "\n",
       "[10190 rows x 51 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ethnicolr import pred_nc_reg_name\n",
    "z = pred_nc_reg_name(namesdf, l, f, num_iter=100, conf_int=.90)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# / ***************************************************************************\n",
    "# Race codes\n",
    "# race               description\n",
    "# *******************************************************************************\n",
    "# A                  ASIAN\n",
    "# B                  BLACK or AFRICAN AMERICAN\n",
    "# I                  AMERICAN INDIAN or ALASKA NATIVE\n",
    "# M                  TWO or MORE RACES\n",
    "# O                  OTHER\n",
    "# P                  NATIVE HAWAIIAN or PACIFIC ISLANDER\n",
    "# U                  UNDESIGNATED\n",
    "# W                  WHITE\n",
    "# *************************************************************************** /\n",
    "\n",
    "# / ***************************************************************************\n",
    "# Ethnic codes\n",
    "# ethnicity          description\n",
    "# *******************************************************************************\n",
    "# HL                 HISPANIC or LATINO\n",
    "# NL                 NOT HISPANIC or NOT LATINO\n",
    "# UN                 UNDESIGNATED\n",
    "# *************************************************************************** /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort and save as ethnicolor_nc_full_pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>white</th>\n",
       "      <th>not_white</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Craig</td>\n",
       "      <td>Abod</td>\n",
       "      <td>0.330625</td>\n",
       "      <td>0.669375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Soliday</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Maigue</td>\n",
       "      <td>0.125258</td>\n",
       "      <td>0.874742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark</td>\n",
       "      <td>Mills</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>0.977124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>Lee</td>\n",
       "      <td>0.162815</td>\n",
       "      <td>0.837185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16305</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16306</th>\n",
       "      <td>Pamela</td>\n",
       "      <td>French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16307</th>\n",
       "      <td>Leesa</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16308</th>\n",
       "      <td>Tim</td>\n",
       "      <td>Donner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16309</th>\n",
       "      <td>Marc</td>\n",
       "      <td>Herman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16310 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      firstname lastname     white  not_white  race\n",
       "0         Craig     Abod  0.330625   0.669375     1\n",
       "1         Brian  Soliday  0.000746   0.999254     1\n",
       "2       Richard   Maigue  0.125258   0.874742     1\n",
       "3          Mark    Mills  0.022876   0.977124     1\n",
       "4          John      Lee  0.162815   0.837185     1\n",
       "...         ...      ...       ...        ...   ...\n",
       "16305   Michael   Arthur       NaN        NaN     0\n",
       "16306    Pamela   French       NaN        NaN     0\n",
       "16307     Leesa    Kelly       NaN        NaN     0\n",
       "16308       Tim   Donner       NaN        NaN     0\n",
       "16309      Marc   Herman       NaN        NaN     0\n",
       "\n",
       "[16310 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = pd.DataFrame(a, columns=[f, l])\n",
    "e['white'] =  z['NL+W_mean'] + z['HL+W_mean']\n",
    "e['not_white'] = 1 - e['white']\n",
    "e['race'] = z['race']\n",
    "\n",
    "race = []\n",
    "\n",
    "        \n",
    "\n",
    "for n in list(e['not_white']):\n",
    "    if n > .50:\n",
    "        #print(True)\n",
    "        race.append(1)\n",
    "    else:\n",
    "        #print(False)  \n",
    "        race.append(0)\n",
    "\n",
    " \n",
    "\n",
    "e['race'] = race\n",
    "e\n",
    "\n",
    "#this doesn't look correct at all. Majority of these names should not be predicted as a minority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done with testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duns</th>\n",
       "      <th>company_name</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>title</th>\n",
       "      <th>gender</th>\n",
       "      <th>flag_owner</th>\n",
       "      <th>flag_presi_vicepresi</th>\n",
       "      <th>prob_nw_eth_wiki</th>\n",
       "      <th>prob_nw_eth_fl_reg_name</th>\n",
       "      <th>prob_nw_eth_fl_five_cat</th>\n",
       "      <th>prob_nw_eth_census_fn</th>\n",
       "      <th>prob_nw_eth_census_ln</th>\n",
       "      <th>prob_nw_eth_nc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08-836-5767</td>\n",
       "      <td>CARAHSOFT TECHNOLOGY CORP.</td>\n",
       "      <td>Craig</td>\n",
       "      <td>Abod</td>\n",
       "      <td>Pres</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037401</td>\n",
       "      <td>0.107029</td>\n",
       "      <td>0.433499</td>\n",
       "      <td>0.130458</td>\n",
       "      <td>0.243278</td>\n",
       "      <td>0.669375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08-836-5767</td>\n",
       "      <td>CARAHSOFT TECHNOLOGY CORP.</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Soliday</td>\n",
       "      <td>President</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066157</td>\n",
       "      <td>0.300205</td>\n",
       "      <td>0.669567</td>\n",
       "      <td>0.325850</td>\n",
       "      <td>0.343575</td>\n",
       "      <td>0.999254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08-836-5767</td>\n",
       "      <td>CARAHSOFT TECHNOLOGY CORP.</td>\n",
       "      <td>Craig</td>\n",
       "      <td>Abod</td>\n",
       "      <td>President</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021443</td>\n",
       "      <td>0.113276</td>\n",
       "      <td>0.499117</td>\n",
       "      <td>0.254797</td>\n",
       "      <td>0.191680</td>\n",
       "      <td>0.874742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08-836-5767</td>\n",
       "      <td>CARAHSOFT TECHNOLOGY CORP.</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Maigue</td>\n",
       "      <td>Owner</td>\n",
       "      <td>MALE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158872</td>\n",
       "      <td>0.247151</td>\n",
       "      <td>0.775649</td>\n",
       "      <td>0.330221</td>\n",
       "      <td>0.206874</td>\n",
       "      <td>0.977124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-836-5767</td>\n",
       "      <td>CARAHSOFT TECHNOLOGY CORP.</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Mills</td>\n",
       "      <td>Vice President and DCO Program Manager</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820681</td>\n",
       "      <td>0.759586</td>\n",
       "      <td>0.980627</td>\n",
       "      <td>0.499882</td>\n",
       "      <td>0.639153</td>\n",
       "      <td>0.837185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18151</th>\n",
       "      <td>61-724-4491</td>\n",
       "      <td>WILLOWCREEK ACADEMY</td>\n",
       "      <td>Pamela</td>\n",
       "      <td>French</td>\n",
       "      <td>Prin</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18152</th>\n",
       "      <td>18-565-3516</td>\n",
       "      <td>HORIZONS TELEVISION, INC.</td>\n",
       "      <td>Leesa</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>Pres</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18153</th>\n",
       "      <td>18-565-3516</td>\n",
       "      <td>HORIZONS TELEVISION, INC.</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Donner</td>\n",
       "      <td>Sec-treas</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18154</th>\n",
       "      <td>96-657-2682</td>\n",
       "      <td>GREEN IT SYSTEMS GROUP</td>\n",
       "      <td>Dirar</td>\n",
       "      <td>Hakeem</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18155</th>\n",
       "      <td>96-657-2682</td>\n",
       "      <td>GREEN IT SYSTEMS GROUP</td>\n",
       "      <td>Marc</td>\n",
       "      <td>Herman</td>\n",
       "      <td>Treas</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              duns                company_name firstname lastname  \\\n",
       "0      08-836-5767  CARAHSOFT TECHNOLOGY CORP.     Craig     Abod   \n",
       "1      08-836-5767  CARAHSOFT TECHNOLOGY CORP.     Brian  Soliday   \n",
       "2      08-836-5767  CARAHSOFT TECHNOLOGY CORP.     Craig     Abod   \n",
       "3      08-836-5767  CARAHSOFT TECHNOLOGY CORP.   Richard   Maigue   \n",
       "4      08-836-5767  CARAHSOFT TECHNOLOGY CORP.      Mark    Mills   \n",
       "...            ...                         ...       ...      ...   \n",
       "18151  61-724-4491         WILLOWCREEK ACADEMY    Pamela   French   \n",
       "18152  18-565-3516   HORIZONS TELEVISION, INC.     Leesa    Kelly   \n",
       "18153  18-565-3516   HORIZONS TELEVISION, INC.       Tim   Donner   \n",
       "18154  96-657-2682      GREEN IT SYSTEMS GROUP     Dirar   Hakeem   \n",
       "18155  96-657-2682      GREEN IT SYSTEMS GROUP      Marc   Herman   \n",
       "\n",
       "                                        title  gender  flag_owner  \\\n",
       "0                                        Pres    MALE           0   \n",
       "1                                   President    MALE           0   \n",
       "2                                   President    MALE           0   \n",
       "3                                       Owner    MALE           1   \n",
       "4      Vice President and DCO Program Manager    MALE           0   \n",
       "...                                       ...     ...         ...   \n",
       "18151                                    Prin  FEMALE           0   \n",
       "18152                                    Pres  FEMALE           0   \n",
       "18153                               Sec-treas    MALE           0   \n",
       "18154                        Managing Partner       -           0   \n",
       "18155                                   Treas    MALE           0   \n",
       "\n",
       "       flag_presi_vicepresi  prob_nw_eth_wiki  prob_nw_eth_fl_reg_name  \\\n",
       "0                         0          0.037401                 0.107029   \n",
       "1                         1          0.066157                 0.300205   \n",
       "2                         1          0.021443                 0.113276   \n",
       "3                         0          0.158872                 0.247151   \n",
       "4                         1          0.820681                 0.759586   \n",
       "...                     ...               ...                      ...   \n",
       "18151                     0               NaN                      NaN   \n",
       "18152                     0               NaN                      NaN   \n",
       "18153                     0               NaN                      NaN   \n",
       "18154                     0               NaN                      NaN   \n",
       "18155                     0               NaN                      NaN   \n",
       "\n",
       "       prob_nw_eth_fl_five_cat  prob_nw_eth_census_fn  prob_nw_eth_census_ln  \\\n",
       "0                     0.433499               0.130458               0.243278   \n",
       "1                     0.669567               0.325850               0.343575   \n",
       "2                     0.499117               0.254797               0.191680   \n",
       "3                     0.775649               0.330221               0.206874   \n",
       "4                     0.980627               0.499882               0.639153   \n",
       "...                        ...                    ...                    ...   \n",
       "18151                      NaN                    NaN                    NaN   \n",
       "18152                      NaN                    NaN                    NaN   \n",
       "18153                      NaN                    NaN                    NaN   \n",
       "18154                      NaN                    NaN                    NaN   \n",
       "18155                      NaN                    NaN                    NaN   \n",
       "\n",
       "       prob_nw_eth_nc  \n",
       "0            0.669375  \n",
       "1            0.999254  \n",
       "2            0.874742  \n",
       "3            0.977124  \n",
       "4            0.837185  \n",
       "...               ...  \n",
       "18151             NaN  \n",
       "18152             NaN  \n",
       "18153             NaN  \n",
       "18154             NaN  \n",
       "18155             NaN  \n",
       "\n",
       "[18156 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergent_true_df['prob_nw_eth_wiki'] = a['not_white']\n",
    "mergent_true_df['prob_nw_eth_fl_reg_name'] = b['not_white']\n",
    "mergent_true_df['prob_nw_eth_fl_five_cat'] = c['not_white']\n",
    "mergent_true_df['prob_nw_eth_census_fn'] = d['not_white']\n",
    "mergent_true_df['prob_nw_eth_census_ln'] = dd['not_white']\n",
    "mergent_true_df['prob_nw_eth_nc'] = e['not_white']\n",
    "mergent_true_df #18156 - 6356\n",
    "# nonull = mergent_true_df. dropna() \n",
    "# nonull\n",
    "mergent_true_df.to_csv('../data/mergent_intellect_executives/mergent_intellect_executives_nlp.csv')\n",
    "mergent_true_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I didn't add the RaceBERT model yet to the dataframe only functions from ethnicolr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huz2ph/.conda/envs/myenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from racebert import RaceBERT\n",
    "# Load the dataset\n",
    "\n",
    "model = RaceBERT()\n",
    "# Concatenate first and last names to form full names\n",
    "namesdf['fullname'] = namesdf['firstname'] + ' ' + namesdf['lastname']\n",
    "# Predict race for all names\n",
    "predicted_race = model.predict_race(namesdf['fullname'])\n",
    "# # Add the predicted race to the original DataFrame\n",
    "#namesdf['predicted_race'] = predicted_race\n",
    "# Create a new DataFrame to store the names and predicted races\n",
    "result_df = pd.DataFrame({'fullname': namesdf['fullname'], 'predicted_race': predicted_race})\n",
    "# # Split the â€˜predicted_raceâ€™ column into â€˜labelâ€™ and â€˜scoreâ€™ columns\n",
    "result_df[['label', 'score']] = result_df['predicted_race'].apply(pd.Series)\n",
    "# # Drop the â€˜predicted_raceâ€™ column\n",
    "result_df.drop('predicted_race', axis=1, inplace=True)\n",
    "\n",
    "result_df\n",
    "len(predicted_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_wh = []\n",
    "\n",
    "scorelist = list(result_df['score'])\n",
    "labellist = list(result_df['label'])\n",
    "\n",
    "for i in range(len(labellist)):\n",
    "    l = labellist[i]\n",
    "    p = scorelist[i]\n",
    "    \n",
    "    if 'nh_white' in l:\n",
    "        not_wh.append(1 - p)\n",
    "    else:\n",
    "        not_wh.append(p)\n",
    "\n",
    "print(len(not_wh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergent_true_df['prob_nw_racebert_fl'] = not_wh\n",
    "# len(not_wh)\n",
    "empty = []\n",
    "for t in list(mergent_true_df['firstname']):\n",
    "    for u in list(results_df['fullname']):\n",
    "        for g in not_wh:\n",
    "                   if t in mergent_true_df[f]:\n",
    "                      empty.append(g)\n",
    "                   else:\n",
    "                      empty.append(None)\n",
    "                       \n",
    "              \n",
    "                \n",
    "empty\n",
    "\n",
    "#mergent_true_df.to_csv('../data/mergent_intellect_executives/mergent_intellect_executives_nlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
