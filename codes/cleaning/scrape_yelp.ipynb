{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape YELP data (also use the YELP API)\n",
    "Notes: A captcha will appear if you run the code one time\n",
    "run it by block with some lage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get asian businesses from Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-341fe99aa85b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdiv_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ul'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'undefined list__09f24__ynIEd'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdiv_element\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiv_elements\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mname_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'css-1egxyvc'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0murl_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# scrape data on asian business in fairfax from yelp\n",
    "i = [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230]\n",
    "filename = '../../data/listings/yelp/clean/yelp_asian.csv'\n",
    "with open(filename, 'a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    run = 0\n",
    "    with open(filename, 'r') as file:\n",
    "        csvreader = csv.reader(file)\n",
    "        for row in csvreader:\n",
    "            if \"company_name\" in row:\n",
    "                run = 1\n",
    "    if run == 0:\n",
    "        writer.writerow(['company_name', 'URL'])\n",
    "\n",
    "        for page in i:\n",
    "            url = 'https://www.yelp.com/search?find_desc=asian+owned+businesses&find_loc=Fairfax%2C+VA&start=' + str(page)\n",
    "\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            div_elements = soup.find('ul', {'class': 'undefined list__09f24__ynIEd'})\n",
    "\n",
    "            for div_element in div_elements:\n",
    "                name_element = div_element.find('span', {'class': 'css-1egxyvc'})\n",
    "                url_element = div_element.find('a')\n",
    "\n",
    "                if name_element is not None and url_element is not None:\n",
    "                    name = name_element.get_text(strip=True)\n",
    "                    url = url_element['href']\n",
    "\n",
    "                    writer.writerow([name, url])\n",
    "\n",
    "    print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the data scraped\n",
    "yelp_asian = pd.read_csv('../../data/listings/yelp/clean/yelp_asian.csv')\n",
    "yelp_asian['source'] = 'yelp asian owned'\n",
    "yelp_asian.to_csv('../../data/listings/yelp/clean/yelp_asian.csv') \n",
    "yelp_asian.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get all black businesses from Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape data on black business in fairfax from yelp\n",
    "i = [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230]\n",
    "\n",
    "filename = '../../data/listings/yelp/clean/yelp_black.csv'\n",
    "with open(filename, 'a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Name', 'URL'])\n",
    "\n",
    "    for page in i:\n",
    "        url = 'https://www.yelp.com/search?find_desc=black+Owned+Businesses&find_loc=Fairfax%2C+VA&start=' + str(page)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        div_elements = soup.find('ul', {'class': 'undefined list__09f24__ynIEd'})\n",
    "\n",
    "        for div_element in div_elements:\n",
    "            name_element = div_element.find('span', {'class': 'css-1egxyvc'})\n",
    "            url_element = div_element.find('a')\n",
    "\n",
    "            if name_element is not None and url_element is not None:\n",
    "                name = name_element.get_text(strip=True)\n",
    "                url = url_element['href']\n",
    "\n",
    "                writer.writerow([name, url])\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the data scraped\n",
    "yelp_black = pd.read_csv('../../data/listings/yelp/clean/yelp_black.csv')\n",
    "yelp_black['source'] = 'yelp black owned'\n",
    "yelp_black.to_csv('../../data/listings/yelp/clean/yelp_black.csv') \n",
    "yelp_black.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get all latino businesses from Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape data on latino business in fairfax from yelp\n",
    "i = [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230]\n",
    "\n",
    "filename = '../../data/listings/yelp/clean/yelp_latino.csv'\n",
    "with open(filename, 'a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Name', 'URL'])\n",
    "\n",
    "    for page in i:\n",
    "        url = 'https://www.yelp.com/search?find_desc=Latinx+Owned+Businesses&find_loc=Fairfax%2C+VA&start=' + str(page)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        div_elements = soup.find('ul', {'class': 'undefined list__09f24__ynIEd'})\n",
    "\n",
    "        for div_element in div_elements:\n",
    "            name_element = div_element.find('span', {'class': 'css-1egxyvc'})\n",
    "            url_element = div_element.find('a')\n",
    "\n",
    "            if name_element is not None and url_element is not None:\n",
    "                name = name_element.get_text(strip=True)\n",
    "                url = url_element['href']\n",
    "\n",
    "                writer.writerow([name, url])\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the data scraped\n",
    "yelp_latino = pd.read_csv('../../data/listings/yelp/clean/yelp_latino.csv')\n",
    "yelp_latino['source'] = 'yelp latino owned'\n",
    "yelp_latino.to_csv('../../data/listings/yelp/clean/yelp_latino.csv') \n",
    "yelp_latino.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get all minority businesses from Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape data on minority owned business in fairfax from yelp\n",
    "i = [0,10,20,30,40,50,60,70,80,90,100,110,120]\n",
    "\n",
    "filename = '../../data/listings/yelp/clean/yelp_minority_owned.csv'\n",
    "with open(filename, 'a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Name', 'URL'])\n",
    "\n",
    "    for page in i:\n",
    "        url = 'https://www.yelp.com/search?find_desc=Minority+Owned&find_loc=Fairfax%2C+VA&start=' + str(page)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        div_elements = soup.find('ul', {'class': 'undefined list__09f24__ynIEd'})\n",
    "        print(div_elements)\n",
    "\n",
    "        for div_element in div_elements:\n",
    "            name_element = div_element.find('span', {'class': 'css-1egxyvc'})\n",
    "            url_element = div_element.find('a')\n",
    "\n",
    "            if name_element is not None and url_element is not None:\n",
    "                name = name_element.get_text(strip=True)\n",
    "                url = url_element['href']\n",
    "\n",
    "                writer.writerow([name, url])\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the data scraped\n",
    "yelp_minority = pd.read_csv('../../data/listings/yelp/clean/yelp_minority_owned.csv')\n",
    "yelp_minority['source'] = 'yelp minority owned'\n",
    "yelp_minority.to_csv('../../data/listings/yelp/clean/yelp_minority_owned.csv') \n",
    "yelp_minority.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Get all businesses from Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230]\n",
    "filename = '../../data/listings/yelp/clean/yelp_all.csv'\n",
    "with open(filename, 'a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    run = 0\n",
    "    with open(filename, 'r') as file:\n",
    "        csvreader = csv.reader(file)\n",
    "        for row in csvreader:\n",
    "            if \"Business Name\" in row:\n",
    "                run = 1\n",
    "    if run == 0:\n",
    "        writer.writerow(['Business Name', 'URL'])\n",
    "\n",
    "        for page in i:\n",
    "            url = 'https://www.yelp.com/search?find_desc=businesses&find_loc=Fairfax%2C+VA&start=' + str(page)\n",
    "\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            div_elements = soup.find('ul', {'class': 'undefined list__09f24__ynIEd'})\n",
    "\n",
    "            for div_element in div_elements:\n",
    "                name_element = div_element.find('span', {'class': 'css-1egxyvc'})\n",
    "                url_element = div_element.find('a')\n",
    "\n",
    "                if name_element is not None and url_element is not None:\n",
    "                    name = name_element.get_text(strip=True)\n",
    "                    for char in name:\n",
    "                        if not char.isalpha():\n",
    "                            name = name.replace(char, \"\")\n",
    "\n",
    "                    url = url_element['href']\n",
    "\n",
    "                    writer.writerow([name, url])\n",
    "\n",
    "    print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the data scraped\n",
    "yelp_all = pd.read_csv('../../data/listings/yelp/clean/yelp_all.csv')\n",
    "yelp_all['source'] = 'yelp all business'\n",
    "yelp_all.to_csv('../../data/listings/yelp/clean/yelp_all.csv') \n",
    "yelp_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data\n",
    "yelp_asian = pd.read_csv('../../data/listings/yelp/clean/yelp_asian.csv')\n",
    "yelp_black = pd.read_csv('../../data/listings/yelp/clean/yelp_black.csv')\n",
    "yelp_latino = pd.read_csv('../../data/listings/yelp/clean/yelp_latino.csv')\n",
    "yelp_minority = pd.read_csv('../../data/listings/yelp/clean/yelp_minority_owned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
